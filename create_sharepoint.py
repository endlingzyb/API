import os
import requests
import html
import time
import random
import json
from datetime import datetime
try:
    from zoneinfo import ZoneInfo
except ImportError:
    from backports.zoneinfo import ZoneInfo

# ================= é…ç½®åŒºåŸŸ =================
DEFAULT_LAT = "39.9042"
DEFAULT_LON = "116.4074"

# ========== å·¥å…·å‡½æ•°ï¼šè·å– access_token ==========
def get_access_token():
    if not os.environ.get("CLIENT_ID"):
        print("âŒ [é”™è¯¯] ç¯å¢ƒå˜é‡ CLIENT_ID æœªæ‰¾åˆ°")
        exit(1)
    client_id = os.environ["CLIENT_ID"]
    client_secret = os.environ["CLIENT_SECRET"]
    tenant_id = os.environ["TENANT_ID"]
    refresh_token = os.environ["GRAPH_REFRESH_TOKEN"]
    
    token_url = f"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token"
    data = {
        "client_id": client_id,
        "client_secret": client_secret,
        "grant_type": "refresh_token",
        "refresh_token": refresh_token,
        "scope": "https://graph.microsoft.com/.default offline_access"
    }
    try:
        resp = requests.post(token_url, data=data, timeout=10)
        if resp.status_code != 200:
            print(f"âŒ è·å– access_token å¤±è´¥: {resp.status_code}")
            exit(1)
        return resp.json()["access_token"]
    except Exception as e:
        print(f"âŒ è·å– Token å¼‚å¸¸: {e}")
        exit(1)

# ========== æ•°æ®è·å– ==========
def get_weather():
    lat = os.environ.get("LATITUDE", DEFAULT_LAT)
    lon = os.environ.get("LONGITUDE", DEFAULT_LON)
    url = "https://api.open-meteo.com/v1/forecast"
    params = {"latitude": lat, "longitude": lon, "daily": "weather_code,temperature_2m_max,temperature_2m_min", "current_weather": "true", "timezone": "auto"}
    try:
        resp = requests.get(url, params=params, timeout=10)
        if resp.status_code == 200:
            data = resp.json()
            daily = data.get("daily", {})
            current = data.get("current_weather", {})
            return {"temp_now": current.get("temperature"), "temp_max": daily.get("temperature_2m_max", ["-"])[0], "temp_min": daily.get("temperature_2m_min", ["-"])[0], "desc": "å¤šäº‘"}
    except Exception: pass
    return None

def get_hitokoto():
    try:
        resp = requests.get("https://v1.hitokoto.cn/?c=d&c=i&c=k", timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            return {"content": data.get("hitokoto"), "from": data.get("from")}
    except Exception: pass
    return {"content": "å¿ƒç³»ä¸€å¤„ï¼Œå®ˆå£å¦‚ç“¶ã€‚", "from": "Unknown"}

# ========== æ ¸å¿ƒé€»è¾‘ï¼šåˆ›å»º SharePoint é¡µé¢ ==========
def create_sharepoint_page(access_token, image_url, weather_data, quote_data):
    headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}

    # 1. æŸ¥æ‰¾ç«™ç‚¹
    target_site_name = os.environ.get("SHAREPOINT_SITE_NAME")
    site_id = None
    if target_site_name:
        print(f"ğŸ” æœç´¢ç«™ç‚¹: '{target_site_name}'")
        search_resp = requests.get(f"https://graph.microsoft.com/v1.0/sites?search={target_site_name}", headers=headers)
        if search_resp.status_code == 200 and search_resp.json().get("value"):
            site_id = search_resp.json()["value"][0]["id"]
            print(f"âœ… é”å®šç«™ç‚¹: {site_id}")
        else:
            print("âŒ æ²¡æ‰¾åˆ°ç«™ç‚¹"); return
    else:
        print("âš ï¸ ä½¿ç”¨ Root ç«™ç‚¹")
        site_id = requests.get("https://graph.microsoft.com/v1.0/sites/root", headers=headers).json()["id"]

    now = datetime.now(ZoneInfo("Asia/Shanghai"))
    page_name = f"Report{now.strftime('%Y%m%d%H%M')}.aspx"
    title_text = f"{now.strftime('%dæ—¥')} | æ¯æ—¥æ™¨æŠ¥"
    
    weather_html = f"<strong>{weather_data['temp_now']}Â°C</strong> ({weather_data['temp_min']}Â° ~ {weather_data['temp_max']}Â°)" if weather_data else "æš‚æ— æ•°æ®"
    quote_html = f"â€œ{html.escape(quote_data['content'])}â€ â€”â€” {html.escape(quote_data['from'])}"

    # ğŸŸ¢ æ„é€  HTML å†…å®¹
    content_html = f"""
    <h2>ğŸ“… ä»Šæ—¥æ¦‚è§ˆ</h2>
    <p>{weather_html}</p>
    <hr>
    <h3>ğŸ’¬ æ¯æ—¥ä¸€è¨€</h3>
    <p><em>{quote_html}</em></p>
    <hr>
    <h3>ğŸ¯ ä»Šæ—¥é‡ç‚¹</h3>
    <ul>
        <li>[ ] é‡è¦äº‹é¡¹ 1</li>
        <li>[ ] é‡è¦äº‹é¡¹ 2</li>
        <li>[ ] é˜…è¯» / å­¦ä¹ </li>
    </ul>
    """

    # ğŸŸ¢ æ„é€  Payload
    payload = {
        # å¿…é¡»æŒ‡å®š OData ç±»å‹
        "@odata.type": "#microsoft.graph.sitePage",
        "name": page_name,
        "title": title_text,
        "pageLayout": "article",
        "titleArea": {
            "enableGradientEffect": True,
            "layout": "colorBlock",
            "showAuthor": True,
            "showPublishedDate": True
        },
        "canvasLayout": {
            "horizontalSections": [
                {
                    # ğŸ”´ å…³é”®ä¿®å¤ï¼šå¿…é¡»æ˜¯å°å†™ 'oneColumn'
                    "layout": "oneColumn", 
                    "id": "1",
                    "emphasis": "none",
                    "columns": [
                        {
                            "id": "1",
                            "width": 12,
                            "webparts": [
                                {
                                    # Text WebPart
                                    "id": "cbe7339d-2718-4d5f-952c-49520c8f6154", 
                                    "innerHtml": content_html
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    }
    
    if image_url:
        payload["titleArea"]["imageWebUrl"] = image_url

    print("ğŸ“ æ­£åœ¨å‘å¸ƒ SharePoint é¡µé¢...")
    
    create_url = f"https://graph.microsoft.com/beta/sites/{site_id}/pages"
    resp = requests.post(create_url, headers=headers, json=payload)
    
    if resp.status_code in [200, 201]:
        print("âœ… é¡µé¢åˆ›å»ºæˆåŠŸï¼")
        
        # å‘å¸ƒ
        page_item_id = resp.json()["id"]
        publish_url = f"https://graph.microsoft.com/beta/sites/{site_id}/pages/{page_item_id}/publish"
        requests.post(publish_url, headers=headers)
        
        pub_url = resp.json().get("webUrl")
        print("ğŸš€ é¡µé¢å·²å‘å¸ƒï¼")
        print(f"ğŸ”— é“¾æ¥: {pub_url}")
        
    else:
        print(f"âŒ åˆ›å»ºå¤±è´¥: {resp.status_code}")
        print(f"ğŸ” é”™è¯¯è¯¦æƒ…: {resp.text}")

# ========== å›¾ç‰‡è·å– ==========
def get_today_image_url(access_token):
    try:
        headers = {"Authorization": f"Bearer {access_token}"}
        folder = "Pictures/Unsplash"
        encoded_path = requests.utils.quote(folder)
        url = f"https://graph.microsoft.com/v1.0/me/drive/root:/{encoded_path}:/children"
        resp = requests.get(url, headers=headers, timeout=20)
        
        if resp.status_code == 200:
            files = resp.json().get("value", [])
            images = [f for f in files if f.get("file")]
            images.sort(key=lambda x: x["name"], reverse=True)
            
            beijing_now = datetime.now(ZoneInfo("Asia/Shanghai"))
            today_prefix = beijing_now.strftime("%Y%m%d")
            selected = next((img for img in images if img["name"].startswith(today_prefix)), images[0] if images else None)
            
            if selected:
                return selected.get("@microsoft.graph.downloadUrl")
    except Exception:
        pass
    return None

# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ SharePoint ç”Ÿæˆå™¨ (å¤§å°å†™ä¿®æ­£ç‰ˆ)...")
    time.sleep(random.randint(1, 3))
    try:
        token = get_access_token()
        weather = get_weather()
        quote = get_hitokoto()
        img_url = get_today_image_url(token)
        create_sharepoint_page(token, img_url, weather, quote)
    except Exception as e:
        print(f"âŒ è„šæœ¬é”™è¯¯: {e}")
        exit(1)